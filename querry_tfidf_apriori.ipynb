{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Building prefix dict from E:\\text_mining\\dict.txt ...\n",
      "DEBUG:jieba:Building prefix dict from E:\\text_mining\\dict.txt ...\n",
      "Loading model from cache c:\\users\\bigdat~1\\appdata\\local\\temp\\jieba.u144803eaa96482ea338b54ad8c7f9634.cache\n",
      "DEBUG:jieba:Loading model from cache c:\\users\\bigdat~1\\appdata\\local\\temp\\jieba.u144803eaa96482ea338b54ad8c7f9634.cache\n",
      "Loading model cost 0.571 seconds.\n",
      "DEBUG:jieba:Loading model cost 0.571 seconds.\n",
      "Prefix dict has been built succesfully.\n",
      "DEBUG:jieba:Prefix dict has been built succesfully.\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "from pymongo import MongoClient \n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "import numpy as np\n",
    "import re\n",
    "import jieba\n",
    "import time\n",
    "#coding=utf-8\n",
    "import sys\n",
    "jieba.set_dictionary('E:/text_mining/dict.txt')             #切換至中文繁體字庫\n",
    "jieba.load_userdict(\"E:/text_mining/dict_keyw_new.txt\")     #加入自建詞庫\n",
    "jieba.load_userdict(\"E:/text_mining/dict_cbdic.txt\")\n",
    "\n",
    "\n",
    "client = MongoClient('10.120.28.20',27017)\n",
    "database = client['test']\n",
    "collection =database['news']\n",
    "\n",
    "def tfIdf(content):\n",
    "    vectorizer = TfidfVectorizer()\n",
    "    X = vectorizer.fit_transform(content)  \n",
    "    weight = X.toarray()\n",
    "    features = vectorizer.get_feature_names()\n",
    "    print \"特徵值數量:\",len(features)\n",
    "    return weight, features\n",
    "\n",
    "\n",
    "def getTopWeight(weight, features, resp_count, top_n):\n",
    "    top_features = []\n",
    "    for n in range(0,resp_count):  #迴圈參考上面的總文章數\n",
    "        indices = np.argsort(weight[n])[::-1]  \n",
    "        # transformer = TfidfTransformer()  #X.toarray()[5] 是第幾篇新聞的意思\n",
    "        \n",
    "        # 看TOP多少的詞\n",
    "        #top_n = 30\n",
    "        top_features.append([features[i] for i in indices[:top_n]]) #這邊的寫法會讓關鍵字中間會有空白\n",
    "    return top_features\n",
    "\n",
    "\n",
    "#def getTopTfidf(news_id,n):\n",
    "#    indices = np.argsort(weight[news_id])[::-1]  \n",
    "#    features = vectorizer.get_feature_names()     \n",
    "#    top_n = n\n",
    "#    top_features = [features[i] for i in indices[:top_n]]\n",
    "#    return top_features,indices, weight\n",
    "#\n",
    "#\n",
    "#def getTopWeight(news_id,n):\n",
    "#    top_features,indices, weight = getTopTfidf(news_id,n)\n",
    "#    #a=0\n",
    "#    for i in top_features:\n",
    "#        #print i,weight[news_id][indices[a]]  # weight[2000] 裡面請填入跟上面一樣的文章編號\n",
    "#        #a=a+1\n",
    "#        return top_features\n",
    "        \n",
    "def apriori(D, minSup):\n",
    "\n",
    "    '''频繁項目集用keys表示，\n",
    "    key表示項目集中的某一項，\n",
    "    cutKeys表示經過修剪的某k項目集。\n",
    "    C表示某k項目集的每一項在D中的支持個數\n",
    "    '''\n",
    "\n",
    "    C1 = {}\n",
    "    for T in D:#跑最外面的list\n",
    "        for I in T:#跑每個大list裡面的小list\n",
    "            if I in C1:#如果裡面的內容有在字典裡面，有的話+1，沒有的話，加入字典初始為1\n",
    "                C1[I] += 1\n",
    "            else:\n",
    "                C1[I] = 1\n",
    "\n",
    "    _keys1 = C1.keys()#取出c1.keys()成為另一個暫時變數(變數名前加上_,為暫時變數)\n",
    "\n",
    "    keys1 = []#把每個keys把他變成獨立的list然後再塞入一個list 成[[A],[B],[C].....]\n",
    "    for i in _keys1:\n",
    "        keys1.append([i])\n",
    "        \n",
    "    \n",
    "    n = len(D)\n",
    "    cutKeys1 = []\n",
    "    for k in keys1[:]:#跑keys1裡的項目，如果項目數量大於最小支持數的話，則加入cutkeys1\n",
    "        if C1[k[0]]*1.0/n >= minSup:\n",
    "            cutKeys1.append(k)\n",
    "    cutKeys1.sort()#排序\n",
    "\n",
    "    keys = cutKeys1#目前項目集裡面的項目(keys)\n",
    "    all_keys = []\n",
    "    while keys != []:\n",
    "        C = getC(D, keys)#計算目前所有個key所在T的數量\n",
    "        cutKeys = getCutKeys(keys, C, minSup, D)#刪掉沒有大於最小支持數的項目keys\n",
    "        for key in cutKeys:\n",
    "            all_keys.append(key)\n",
    "        keys = aproiri_gen(cutKeys)\n",
    "    return all_keys\n",
    "\n",
    "def getC(D, keys):\n",
    "    '''對目前尚有的keys進行計數'''\n",
    "    C = []\n",
    "    for key in keys:\n",
    "        c = 0\n",
    "        for T in D:\n",
    "            have = True\n",
    "            for k in key:\n",
    "                if k not in T:\n",
    "                    have = False\n",
    "            if have:\n",
    "                c += 1\n",
    "        C.append(c)\n",
    "    return C\n",
    "\n",
    "def getCutKeys(keys, C, minSup, D):\n",
    "    '''判斷這個項目有沒有大於最小支持數'''\n",
    "    for key in keys[:]:\n",
    "        num = 0\n",
    "        for T in D:\n",
    "            if keyInT(key, T):\n",
    "                num += 1\n",
    "        if num * 1.0 / len(D) < minSup:\n",
    "            keys.remove(key)\n",
    "\n",
    "    return keys\n",
    "\n",
    "def keyInT(key, T):\n",
    "    '''判斷項目keys有沒有在項目集T裡面'''\n",
    "    for k in key:\n",
    "        if k not in T:\n",
    "            return False\n",
    "    return True\n",
    "\n",
    "def aproiri_gen(keys1):\n",
    "    '''連起來'''\n",
    "    keys2 = []\n",
    "    for k1 in keys1:\n",
    "        for k2 in keys1:\n",
    "            if k1 != k2:\n",
    "                key = []\n",
    "                for k in k1:\n",
    "                    if k not in key:\n",
    "                        key.append(k)\n",
    "                for k in k2:\n",
    "                    if k not in key:\n",
    "                        key.append(k)\n",
    "                key.sort()\n",
    "                if key not in keys2:\n",
    "                    keys2.append(key)\n",
    "    return keys2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "查詢結果的第一筆資料標題: 想想那些爬電塔的人,（許又方）\n",
      "查詢結果資料總筆數: 7802\n",
      "quuerry+jieba的時間 42.5917606756 秒\n",
      "特徵值數量: 137032\n",
      "計算tf-idf的時間 2.78908597899 秒\n",
      "排序與取值的時間 17.0077702959 秒\n"
     ]
    }
   ],
   "source": [
    "time_start = time.clock()\n",
    "content =[]\n",
    "\n",
    "#拿資料\n",
    "#2013-01-0X; 2013-01-1x;...可行\n",
    "#201301 % 23\n",
    "#201406 % 16\n",
    "#20160101~05 % 17\n",
    "#20150421 % 28\n",
    "\n",
    "tag1 = \"台灣\"\n",
    "tag2 = \"颱風\"\n",
    "\n",
    "querry_resp = collection.find({\"$and\":[\n",
    "            {\"content\":{\"$regex\":tag1}},\n",
    "            {\"content\":{\"$regex\":tag2}},\n",
    "        ]})\n",
    "#querry_resp = collection.find({\n",
    "#        \"date\":{\"$regex\":\"201601\"}\n",
    "#    })\n",
    "\n",
    "print \"查詢結果的第一筆資料標題:\",querry_resp[0][\"title\"]\n",
    "\n",
    "for post in querry_resp: \n",
    "    summary = post['content']\n",
    "    content.append('/'.join(jieba.cut(summary)))\n",
    "    #title.append(post['title'])\n",
    "    \n",
    "#總文章數量\n",
    "resp_count = querry_resp.count()\n",
    "print \"查詢結果資料總筆數:\", resp_count\n",
    "time_step1 = time.clock()\n",
    "print \"quuerry+jieba的時間\", time_step1-time_start, \"秒\"\n",
    "\n",
    "weight, features = tfIdf(content)\n",
    "time_step2 = time.clock()\n",
    "print \"計算tf-idf的時間\", time_step2-time_step1, \"秒\"\n",
    "\n",
    "#resp_num #querr回來的第幾篇\n",
    "top_num = 20   #取tf-idf前幾高的\n",
    "tf_idf_resp = getTopWeight(weight, features, resp_count, top_num)\n",
    "time_step3 = time.clock()\n",
    "print \"排序與取值的時間\", time_step3-time_step2, \"秒\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "總共有 156040 個詞\n",
      "其中共有 55109 個不重複的詞\n",
      "每個詞平均重複出現 2.83147943167 次\n",
      "標準差 7.34410207822 次\n",
      "------------------\n",
      "列出次數最高的前20個詞與次數:\n",
      "氣象局 416\n",
      "颱風 288\n",
      "公里 236\n",
      "毫米 211\n",
      "路徑 197\n",
      "中心 197\n",
      "台灣 197\n",
      "影響 193\n",
      "天氣 188\n",
      "海面 184\n",
      "北部 177\n",
      "蘇迪勒 174\n",
      "昌鴻 172\n",
      "高溫 172\n",
      "中央氣象局 169\n",
      "發布 158\n",
      "東半部 155\n",
      "降雨 146\n",
      "菲律賓 143\n",
      "暴風圈 142\n",
      "------------------\n",
      "門檻設定為mean的2個標準差範圍 17.5196835881 次\n",
      "共 1169.0 個詞大於門檻\n",
      "第 1169.0 的詞實際排在前 2.12125061242 %\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "print \"總共有\", resp_count * top_num, \"個詞\"\n",
    "dic = {}  #統計出現次數\n",
    "for top20_list in tf_idf_resp:\n",
    "    for ele in top20_list:\n",
    "        if not ele in dic:\n",
    "            dic[ele] = 1\n",
    "        else:\n",
    "            dic[ele] = dic[ele] + 1\n",
    "print \"其中共有\",len(dic),\"個不重複的詞\"\n",
    "\n",
    "lis = sorted(dic.items(), key=lambda dic:dic[1], reverse= True)\n",
    "\n",
    "total = 0.0\n",
    "for ele in lis[:]:\n",
    "    #print ele[0], ele[1]\n",
    "    total += ele[1]\n",
    "#print \"詞的總次數\", total\n",
    "\n",
    "mean = total / len(dic)\n",
    "print \"每個詞平均重複出現\", mean, \"次\"\n",
    "#max_count_item = max(lis, key=lambda x:x[1])\n",
    "#min_count_item = min(lis, key=lambda x:x[1])\n",
    "#print max_count_item[0], min_count_item[0]\n",
    "\n",
    "#求標準差\n",
    "err = 0\n",
    "for ele in lis[:]:\n",
    "    x = ele[1]\n",
    "    err += (x - mean)**2\n",
    "sd = (err/len(dic))**0.5\n",
    "print \"標準差\", sd, \"次\"\n",
    "print \"------------------\"\n",
    "print \"列出次數最高的前20個詞與次數:\"\n",
    "for ele in lis[0:20]:\n",
    "    print ele[0], ele[1]\n",
    "#    print dic.items()[i][0], dic.items()[i][1] #上下兩行效果相等\n",
    "print \"------------------\"\n",
    "#根據Chebyshev不等式(Chebyshev's Inequality)\n",
    "#mean的1個標準差範圍內至少包含約50%的資料\n",
    "#mean的2個標準差範圍內至少包含約75%的資料\n",
    "#mean的3個標準差範圍內至少包含約89%的資料\n",
    "treshold = mean+2*sd\n",
    "print \"門檻設定為mean的2個標準差範圍\", treshold, \"次\" #大於此門檻次數的詞就是保證排名在前25%內的詞\n",
    "\n",
    "count = 0.0\n",
    "for ele in lis[:]:\n",
    "    if ele[1] > treshold:\n",
    "        #print ele[0], ele[1]\n",
    "        count+=1\n",
    "print \"共\", count, \"個詞大於門檻\"\n",
    "rank = count/len(dic)\n",
    "print \"第\", count, \"的詞實際排在前\",rank*100,\"%\" \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "購物籃分析的時間 2.27533856648 秒\n",
      "\n",
      "傳回 15 組關聯分析結果:\n",
      "與查詢詞 台灣 颱風 常出現的詞:\n",
      "中央氣象局\n",
      "中心\n",
      "公里\n",
      "北部\n",
      "台灣\n",
      "天氣\n",
      "影響\n",
      "昌鴻\n",
      "毫米\n",
      "氣象局\n",
      "海面\n",
      "蘇迪勒\n",
      "路徑\n",
      "颱風\n",
      "高溫\n"
     ]
    }
   ],
   "source": [
    "time_step4 = time.clock()\n",
    "D = apriori(tf_idf_resp, rank) #購物籃分析\n",
    "time_step5 = time.clock()\n",
    "print \"購物籃分析的時間\",  time_step5-time_step4, \"秒\"\n",
    "print \"\"\n",
    "\n",
    "print \"傳回\", len(D), \"組關聯分析結果:\"\n",
    "print \"與查詢詞\", tag1, tag2, \"常出現的詞:\"\n",
    "for ele in D:\n",
    "    if len(ele)>2:\n",
    "        print (\",\".join(ele))\n",
    "    else:\n",
    "        print ele[0]\n",
    "\n",
    "\n",
    "        \n",
    "#測試結果: 查詢詞1+查詢詞2, 查到篇數, 關聯分析組數, 關聯分析時間         \n",
    "#馬英九+蔡英文, 6473篇, 50組, 13.6秒\n",
    "#王建民+大聯盟, 3159篇 79組, 14.26秒\n",
    "#大數據+雲端, 855篇, 33組, 0.82秒\n",
    "#酒駕+死亡, 1032篇, 2組, 0.016秒\n",
    "#颱風+台灣, 7802篇, 15組, 2.275秒"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
